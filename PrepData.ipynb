{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bz2file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7598ac27f729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This module will prep the data set for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbz2file\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bz2file'"
     ]
    }
   ],
   "source": [
    "# This module will prep the data set for training\n",
    "import pandas as pd\n",
    "import bz2file as bz2\n",
    "import json\n",
    "\n",
    "def loadData():\n",
    "    '''\n",
    "    Returns the dataframe after loading from raw data, while remove unnecessary columns\n",
    "    '''\n",
    "    # Load data into dataframe\n",
    "    data = bz2.open(\"Data/20200325_counsel_chat.csv.bz2\")\n",
    "    df = pd.read_csv(data)\n",
    "    # Remove unneccessary input data\n",
    "    df = df.drop(columns=['questionID', 'upvotes', 'views', 'questionLink', 'therapistInfo', 'therapistURL'])\n",
    "    # fun idea, use therapist url to do webscraping to build the persona.\n",
    "    \n",
    "    df.insert(0, \"TherapyPersona\", \"Emotion\")  ### This is an abstraction over topic to deal with classimbalance/limited data\n",
    "    return df\n",
    "    \n",
    "\n",
    "def switch(topic):\n",
    "    '''\n",
    "\tReturns a the Therapy Persona type corresponding to the topic\n",
    "\tArguments:\n",
    "\t- topic: Dataframe with comments and their corresponding toxicities \n",
    "    '''\n",
    "    switcher = {\n",
    "        #emotion categories\n",
    "        \"anxiety\": \"Emotion\",\n",
    "        \"anger-management\": \"Emotion\",\n",
    "        \"depression\": \"Emotion\",\n",
    "        \"stress\": \"Emotion\",\n",
    "        \"spirituality\": \"Emotion\",\n",
    "        \"human-sexuality\": \"Emotion\",\n",
    "        \"self-esteem\": \"Emotion\",\n",
    "        \"intimacy\": \"Emotion\",\n",
    "        \"children-adolescents\": \"Emotion\",\n",
    "        \"behavioral-change\": \"Emotion\",\n",
    "        \"counseling-fundamentals\": \"Emotion\",\n",
    "        \"relationships\": \"Emotion\",\n",
    "        \"grief-and-loss\": \"Emotion\",\n",
    "\n",
    "        #experiential categories\n",
    "        \"legal-regulatory\": \"Experiential\",\n",
    "        \"trauma\": \"Experiential\",\n",
    "        \"workplace-relationships\": \"Experiential\",\n",
    "        \"substance-abuse\": \"Experiential\",\n",
    "        \"lgbtq\": \"Experiential\",\n",
    "        \"addiction\": \"Experiential\",\n",
    "        \"parenting\": \"Experiential\",\n",
    "        \"social-relationships\": \"Experiential\",\n",
    "        \"sleep-improvement\": \"Experiential\",\n",
    "        \"relationship-dissolution\": \"Experiential\",\n",
    "        \"military-issues\": \"Experiential\",\n",
    "        \"diagnosis\": \"Experiential\",\n",
    "        \"family-conflict\": \"Experiential\",\n",
    "        \"eating-disorders\": \"Experiential\",\n",
    "        \"marriage\":\"Experiential\",\n",
    "        \"domestic-violence\": \"Experiential\",\n",
    "        \"self-harm\": \"Experiential\",\n",
    "        \"professional-ethics\": \"Experiential\"\n",
    "    }\n",
    "    return switcher.get(topic, \"Emotion\")\n",
    "\n",
    "def removeEmpty(df):\n",
    "    '''\n",
    "\tReturns the data frame after removing empty rows from data\n",
    "\tArguments:\n",
    "\t- df: Dataframe with the questions, answers, and topics\n",
    "    '''\n",
    "    nan_value = float(\"NaN\")\n",
    "    df.replace(\"\", nan_value, inplace=True)\n",
    "    df.dropna(subset = [\"questionText\", \"questionTitle\", \"answerText\"], inplace=True)\n",
    "    return df\n",
    "    \n",
    "def setPersona(df):\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'TherapyPersona'] = switch(row['topic'])\n",
    "    return df\n",
    "\n",
    "#Split Data\n",
    "def SplitandSave(df):\n",
    "    print(df.groupby('split').count())\n",
    "\n",
    "    train_df = df[df.split == 'train']\n",
    "    test_df = df[df.split == 'test']\n",
    "    val_df = df[df.split == 'val']\n",
    "\n",
    "    #Save sets\n",
    "#     train_df.to_csv ('Data/Train.csv', index = False, header=True)\n",
    "#     test_df.to_csv ('Data/Test.csv', index = False, header=True)\n",
    "#     val_df.to_csv ('Data/Val.csv', index = False, header=True)\n",
    "    \n",
    "    return train_df, test_df, val_df\n",
    "\n",
    "def setupEmotion(train_df, test_df, val_df):\n",
    "    #####################Train Data##########################\n",
    "    EmotionDF = train_df[train_df.TherapyPersona == 'Emotion']\n",
    "    data_set = [{\"personality\": [\"How did that make you feel?\", \"I want to get to the source of these feelings.\"], \n",
    "                \"utterances\": [{\"candidates\": [], \"history\": []}]}]\n",
    "    i = 0\n",
    "    for index, row in EmotionDF.iterrows():\n",
    "        Question = row['questionText']\n",
    "        Answer =  row['answerText']\n",
    "        numCandidates = len(data_set[0][\"utterances\"][i][\"candidates\"])\n",
    "        if(i==100):\n",
    "            break\n",
    "        if(i != len(EmotionDF) - 1):\n",
    "            data_set[0][\"utterances\"].append({\"candidates\": [], \"history\": []})\n",
    "        if(numCandidates < 1):\n",
    "            data_set[0][\"utterances\"][i][\"candidates\"].append(Answer)\n",
    "            data_set[0][\"utterances\"][i][\"history\"].append(Question)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    json_dump = json.dumps(data_set)\n",
    "    EmotionPersona = json.loads(json_dump)\n",
    "\n",
    "    with open('Data/EmotionPersona.json', 'w') as outfile:\n",
    "        json.dump(EmotionPersona, outfile)\n",
    "    \n",
    "    #####################Test Data##########################\n",
    "    test_EmotionDF = test_df[test_df.TherapyPersona == 'Emotion']\n",
    "    data_set = [{\"personality\": [\"How did that make you feel?\", \"I want to get to the source of these feelings.\"], \n",
    "                \"utterances\": [{\"candidates\": [], \"history\": []}]}]\n",
    "    i = 0\n",
    "    for index, row in EmotionDF.iterrows():\n",
    "        Question = row['questionText']\n",
    "        Answer =  row['answerText']\n",
    "        numCandidates = len(data_set[0][\"utterances\"][i][\"candidates\"])\n",
    "        if(i==100):\n",
    "            break\n",
    "        if(i != len(test_EmotionDF) - 1):\n",
    "            data_set[0][\"utterances\"].append({\"candidates\": [], \"history\": []})\n",
    "        if(numCandidates < 1):\n",
    "            data_set[0][\"utterances\"][i][\"candidates\"].append(Answer)\n",
    "            data_set[0][\"utterances\"][i][\"history\"].append(Question)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    json_dump = json.dumps(data_set)\n",
    "    test_EmotionPersona = json.loads(json_dump)\n",
    "\n",
    "    with open('Data/EmotionPersonaTest.json', 'w') as outfile:\n",
    "        json.dump(EmotionPersona, outfile)\n",
    "\n",
    "def setupExperential(train_df, test_df, val_df):\n",
    "    #####################Train Data##########################\n",
    "    ExperentialDF = train_df[train_df.TherapyPersona == 'Experiential']\n",
    "    data_set = [{\"personality\": [\"Tell me more about the situation?\", \"Has this happened before in the past?\"], \n",
    "                \"utterances\": [{\"candidates\": [], \"history\": []}]}]\n",
    "    i = 0\n",
    "    for index, row in ExperentialDF.iterrows():\n",
    "        Question = row['questionText']\n",
    "        Answer =  row['answerText']\n",
    "        numCandidates = len(data_set[0][\"utterances\"][i][\"candidates\"])\n",
    "        if(i==100):\n",
    "            break\n",
    "        if(i != len(ExperentialDF) - 1):\n",
    "            data_set[0][\"utterances\"].append({\"candidates\": [], \"history\": []})\n",
    "        if(numCandidates < 1):\n",
    "            data_set[0][\"utterances\"][i][\"candidates\"].append(Answer)\n",
    "            data_set[0][\"utterances\"][i][\"history\"].append(Question)\n",
    "        i += 1\n",
    "\n",
    "            \n",
    "    json_dump = json.dumps(data_set)\n",
    "    ExperentialPersona = json.loads(json_dump)\n",
    "\n",
    "    with open('Data/ExperentialPersonaTest.json', 'w') as outfile:\n",
    "        json.dump(ExperentialPersona, outfile)\n",
    "    \n",
    "    #####################Test Data##########################\n",
    "    test_ExperentialDF = test_df[test_df.TherapyPersona == 'Experiential']\n",
    "    data_set = [{\"personality\": [\"Tell me more about the situation?\", \"Has this happened before in the past?\"], \n",
    "                \"utterances\": [{\"candidates\": [], \"history\": []}]}]\n",
    "    i = 0\n",
    "    for index, row in ExperentialDF.iterrows():\n",
    "        Question = row['questionText']\n",
    "        Answer =  row['answerText']\n",
    "        numCandidates = len(data_set[0][\"utterances\"][i][\"candidates\"])\n",
    "        if(i==100):\n",
    "            break\n",
    "        if(i != len(test_ExperentialDF) - 1):\n",
    "            data_set[0][\"utterances\"].append({\"candidates\": [], \"history\": []})\n",
    "        if(numCandidates < 1):\n",
    "            data_set[0][\"utterances\"][i][\"candidates\"].append(Answer)\n",
    "            data_set[0][\"utterances\"][i][\"history\"].append(Question)\n",
    "        i += 1\n",
    "\n",
    "            \n",
    "    json_dump = json.dumps(data_set)\n",
    "    test_ExperentialPersona = json.loads(json_dump)\n",
    "\n",
    "    with open('Data/ExperentialPersona.json', 'w') as outfile:\n",
    "        json.dump(ExperentialPersona, outfile)\n",
    "\n",
    "\n",
    "def PrepData():\n",
    "    df = loadData()\n",
    "    df = removeEmpty(df)\n",
    "    df = setPersona(df)\n",
    "    SplitandSave(df)\n",
    "    return df\n",
    "\n",
    "def PrepPersonaData():\n",
    "    df = loadData()\n",
    "    df = removeEmpty(df)\n",
    "    df = setPersona(df)\n",
    "    train_df, test_df, val_df = SplitandSave(df)\n",
    "    setupEmotion(train_df, test_df, val_df)\n",
    "    setupExperential(train_df, test_df, val_df)\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "PrepPersonaData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c00600aa288a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install bz2file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawnb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pexpect-U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<pexpect factory incomplete>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 304\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptyproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_spawnpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_native_pty_fork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Use internal fork_pty, for Solaris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pty.py\u001b[0m in \u001b[0;36mfork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmaster_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslave_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Establish a new session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "!pip3 install bz2file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
